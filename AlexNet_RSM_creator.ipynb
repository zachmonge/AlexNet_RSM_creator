{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script written by Zach Monge to create representational similarity matrices (RSMs) from layers of the AlexNet (pretrained on the ImageNet dataset).\n",
    "\n",
    "\n",
    "I ran this script on Google Cloud Platform with a NVIDIA Tesla K80 GPU. Parts of this script were taken from https://github.com/CSAILVision/places365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing functions. For the deep learning library I am using PyTorch\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d (3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "    (3): Conv2d (64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "    (6): Conv2d (192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d (384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing AlexNet model pretrained on ImageNet\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "model = alexnet\n",
    "\n",
    "# Shutting off dropoff since we are only evaluating and not training the model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2751.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8480.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1275.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6243.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9050.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     image\n",
       "0   1  2751.jpg\n",
       "1   2  8480.jpg\n",
       "2   3  1275.jpg\n",
       "3   4  6243.jpg\n",
       "4   5  9050.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying the Path in which the images were saved\n",
    "PATH = '/home/zachm/neuro/resized/'\n",
    "\n",
    "# Importing the CSV file that contains the id number for each image and the image filename\n",
    "image_df=pd.read_csv(f'{PATH}image_ids.csv')\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image transformer\n",
    "centre_crop = trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now will submit each image to AlexNet and loop through each layer to obtain the activation values. For each image at each layer, I output the activation values, which are vectorized and then stored in a Pandas dataframe. So the output of the below cell is for each layer a Pandas dataframe, where each column is the activation values for an image.\n",
    "\n",
    "First this is done for the covolutional layers (first five layers) and then the fully-connected layers (last three layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First for the convolutional layers\n",
    "for layer_number in range(len(model.features)):\n",
    "    layer_number_count = layer_number+1\n",
    "    \n",
    "    # Create a temporary model in which the last layer is the layer of interest within the loop\n",
    "    temp_model=nn.Sequential(*list(model.features.children())[0:layer_number_count])\n",
    "    \n",
    "    # Creating df for layer\n",
    "    vars()[f'layer_{layer_number_count}']=pd.DataFrame()\n",
    "    \n",
    "    # Forward passing the image through the model\n",
    "    for img_name in image_df['image']:\n",
    "        \n",
    "        #Opening image\n",
    "        try:\n",
    "            img = Image.open(f'{PATH}{img_name}')\n",
    "        except:\n",
    "            img = Image.open(f'{PATH}{img_name[:-4]}.JPG')\n",
    "            \n",
    "        input_img = V(centre_crop(img).unsqueeze(0), volatile=True)\n",
    "\n",
    "        # Forward pass image through the model\n",
    "        feature_values = temp_model.forward(input_img)\n",
    "        \n",
    "        #Vectorizing torch tensor\n",
    "        element_size=np.prod(np.array(feature_values.data.size()))\n",
    "        feature_values_vec=feature_values.view(np.int(element_size),1)\n",
    "        feature_values_vec_np=feature_values_vec.data.numpy()\n",
    "        \n",
    "        # Putting activation values into the layer df\n",
    "        vars()[f'layer_{layer_number_count}'][img_name]=feature_values_vec_np.flatten()\n",
    "\n",
    "#Now for the fully connected layers   \n",
    "for layer_number in range(len(model.classifier)):\n",
    "    \n",
    "    # Resetting the model here. I found if I did not do this the script did not run properly\n",
    "    alexnet = models.alexnet(pretrained=True)\n",
    "    model = alexnet\n",
    "    model.eval()\n",
    "    \n",
    "    # Just a few small specifications such as the layer number\n",
    "    layer_number_count = layer_number_count+1\n",
    "    layer_number_count_iteration = layer_number+1\n",
    "    temp_model_classifier_layers = model\n",
    "    \n",
    "    # Create a temporary model in which the last layer is the layer of interest within the loop\n",
    "    new_classifier=nn.Sequential(*list(temp_model_classifier_layers.classifier.children())[0:layer_number_count_iteration])\n",
    "    temp_model_classifier_layers.classifier = new_classifier\n",
    "    \n",
    "    # Creating df for layer\n",
    "    vars()[f'layer_{layer_number_count}']=pd.DataFrame()\n",
    "    \n",
    "    # Forward passing the image through the model\n",
    "    for img_name in image_df['image']:\n",
    "        \n",
    "        #Opening image\n",
    "        try:\n",
    "            img = Image.open(f'{PATH}{img_name}')\n",
    "        except:\n",
    "            img = Image.open(f'{PATH}{img_name[:-4]}.JPG')\n",
    "        input_img = V(centre_crop(img).unsqueeze(0), volatile=True)\n",
    "\n",
    "        # Forward pass image through the model\n",
    "        feature_values = temp_model_classifier_layers.forward(input_img)\n",
    "        \n",
    "        #Vectorizing torch tensor\n",
    "        element_size=np.prod(np.array(feature_values.data.size()))\n",
    "        feature_values_vec=feature_values.view(np.int(element_size),1)\n",
    "        feature_values_vec_np=feature_values_vec.data.numpy()\n",
    "        \n",
    "        # Putting activation values into the layer df\n",
    "        vars()[f'layer_{layer_number_count}'][img_name]=feature_values_vec_np.flatten()\n",
    "        \n",
    "# Taking the last layer and running it through a softmax activation function. This is commonly done within deep learning.\n",
    "last_layer_number = layer_number_count\n",
    "layer_number_count = layer_number_count+1\n",
    "# Creating df for the last layer\n",
    "vars()[f'layer_{layer_number_count}']=pd.DataFrame()\n",
    "for img_name in image_df['image']:\n",
    "    vars()[f'layer_{layer_number_count}'][img_name]=softmax(vars()[f'layer_{last_layer_number}'][img_name].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each layer, will now take the activation values for each image within each dataframe, and correlate them with each other. This will create a stimuli model for each layer.\n",
    "\n",
    "Here I have it set to do a Pearson correlation and to place NaNs on the diagonal, but this can be easily changed by making minor edits to the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(layer_number_count):\n",
    "    i = i+1\n",
    "    vars()[f'layer_{i}_corr_matrix'] = vars()[f'layer_{i}'].corr(method = 'pearson')\n",
    "    \n",
    "    # Places the value 5 on the diagonol so will be NaNed\n",
    "    np.fill_diagonal(vars()[f'layer_{str(i)}_corr_matrix'].values,5)\n",
    "    vars()[f'layer_{i}_corr_matrix_nan'] = vars()[f'layer_{i}_corr_matrix'][vars()[f'layer_{i}_corr_matrix']<5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the Representatioanl Similarity Analysis, I typically using scripts written within Matlab (https://github.com/brg015). So I output the correlation matrices into a .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting numpy matrixes to MATLAB .mat files\n",
    "\n",
    "# Order of image ID in matrices. This wll be specific to your images. \n",
    "# Within the current study, the image IDs ranged from 1 to 420.\n",
    "stim_ID_num=np.arange(1,421)\n",
    "\n",
    "# Specify path where to save .mat files\n",
    "matlab_data_path = '/home/zachm/neuro/RDMs/EmoLOP_AlexNet/'\n",
    "\n",
    "# Exporting each layer to .mat file. The two variables contained within the MAT file are R (the correlation matrix)\n",
    "# and stim_ID_num (the order of iamge ID in matrices). Again, this was done to work with the MATLAB scripts\n",
    "for j in range(last_layer_number+1):\n",
    "    layer_number_count = j+1\n",
    "    savemat(f'{matlab_data_path}layer_{layer_number_count}_corr_matrix_nan',{\"R\": vars()['layer_'+str(layer_number_count)+'_corr_matrix_nan'].values,\"stim_ID_num\":stim_ID_num})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
